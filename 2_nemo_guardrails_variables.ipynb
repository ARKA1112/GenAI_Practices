{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colang_content = \"\"\"\n",
    "define user greeting\n",
    "    \"Hey there!\"\n",
    "    \"How are you?\"\n",
    "    \"What's up?\"\n",
    "    \n",
    "define bot name greeting\n",
    "    \"Hey $name!\"\n",
    "\n",
    "\n",
    "define flow\n",
    "    user greeting\n",
    "    if $name\n",
    "        bot name greeting\n",
    "    else\n",
    "        bot greeting\n",
    "        \n",
    "# define limits\n",
    "define user ask politics\n",
    "    \"what are your political beliefs?\"\n",
    "    \"thoughts on the president?\"\n",
    "    \"left wing\"\n",
    "    \"right wing\"\n",
    "    \"\"\"\n",
    "\n",
    "yaml_content = \"\"\"\n",
    "models:\n",
    "- type: main\n",
    "  engine: openai\n",
    "  model: gpt-3.5-turbo-16k\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# initialize rails config\n",
    "config = RailsConfig.from_content(\n",
    "    colang_content=colang_content,\n",
    "    yaml_content=yaml_content\n",
    ")\n",
    "\n",
    "#create rails\n",
    "\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role':'context', \"content\":\"\"},\n",
    "    {'role':'user',\"content\":\"Hey there!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': 'Hey there! How can I assist you today?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await rails.generate_async(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"I can definitely help you with that! To find a political party to join, I would recommend considering your own political beliefs and values. You can research different political parties and their platforms to see which aligns most closely with your own views. Additionally, you can attend local political events or meetings to learn more about different parties and connect with like-minded individuals. It's important to be an informed voter and actively participate in the political process. Let me know if there's anything specific you'd like assistance with!\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"context\", \"content\": {\"name\": \"Arka\"}},\n",
    "    {\"role\": \"assistant\",\n",
    "     \"content\": \"Hi! How are you? Is there anything I can help with?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Find me a political party to join\"}\n",
    "]\n",
    "     \n",
    "await rails.generate_async(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the above answer we can clearly assume that we need to provide more context to it in order to deal with political issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RailsConfig.from_content(\n",
    "    colang_content=colang_content,\n",
    "    yaml_content=yaml_content\n",
    ")\n",
    "\n",
    "\n",
    "#create rails\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"I'm sorry, but I can't assist with finding a political party for you to join. It's a personal decision that depends on your beliefs, values, and priorities. I recommend doing some research and exploring different political parties to find one that aligns with your views.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = await rails.generate_async(messages=messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo-16k in organization org-nXqwFsbc9DcAFxyTEkiHXwz6 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    }
   ],
   "source": [
    "messages += [\n",
    "    res,\n",
    "    {'role':'user','content':\"Im Arka\"}\n",
    "]\n",
    "\n",
    "res = await rails.generate_async(messages=messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
